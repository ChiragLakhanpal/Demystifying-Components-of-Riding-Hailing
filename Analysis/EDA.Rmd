---
title: "Demystifying Components of Riding Hailing"
author: "Chirag Lakhanpal, Shikha Sharma, Abhishek Pradhan"
# date: "today"
output:
  html_document:
    code_folding: hide
    number_sections: false
    toc: yes
    toc_depth: 3
    toc_float: yes
  pdf_document:
    toc: yes
    toc_depth: '3'
---

<style type="text/css">
  body{
  font-size: 10pt;
  font-family: 'Calibri';

@media (prefers-color-scheme: dark) {
  img {
    opacity: .75;
    transition: opacity .5s ease-in-out;
  }
  img:hover {
    opacity: 1;
  }
  }
}
</style>

```{r init, include=FALSE}
# Installing necessary packages 
library(arrow)
library(ezids)
library(knitr)
library(dplyr)
library(lubridate)
library(ggplot2)
library(reshape2)

# knitr::opts_chunk$set(warning = F, results = "markup", message = F)
knitr::opts_chunk$set(warning = F, results = "hide", message = F)
#options(scientific=T, digits = 3) 
options(scipen=9, digits = 3) 
# ‘scipen’: integer. A penalty to be applied when deciding to print numeric values in fixed or exponential notation.  Positive values bias towards fixed and negative towards scientific notation: fixed notation will be preferred unless it is more than ‘scipen’ digits wider.
# use scipen=999 to prevent scientific notation at all times
#options(scipen=999)
```

## 1 Exordium

##### One of the most famous pictures of New York is the wave of yellow taxi taxis flooding the streets. So, where better to research taxi cab data than New York City? This is exactly what we intended to do. From 2009 until the present, the NYC Taxi and Limousine Commission (TLC) has gathered massive amounts of data for every taxi travel in New York City. We set out to get our hands dirty and put the sophisticated analysis,we learnt over the semester to work.


##### **We wanted to see how parameters like pick-up location, distance, number of passengers, and drop-off location impact the tipping behavior of NYC taxi drivers.**



## 2 Data Preparation

### 2.1 Data Gathering

```{r Reading Data, results='markup',echo=FALSE}

# Loading main data for New York yellow taxi trips
raw_data <- data.frame(read_parquet('../Data/yellow_tripdata_2022-06.parquet'))

# Loading main data for Zone information
zone_lookup <- data.frame(read.csv("../Data/Taxi_Zone_Lookup.csv"))

data_des <- data.frame(read.csv('../Data/Data_Definitions.csv'))

kable(str(raw_data),bso='bordered', title = 'Glimpse of Raw Data')

```

##### **Comments** :  At a first glance, there are total `r nrow(raw_data)*ncol(raw_data)` observation across `r nrow(raw_data)` and `r ncol(raw_data)` variables in which 7 are categorical and 12 are numerical variables. The data was procured from the NYC Open Source GIS website - https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page.

### 2.2 Data Descriptors

```{r, results='markup',echo=FALSE}
xkabledply((data_des),bso='bordered', title = 'Zones', pos = 'center')
```

##### **Comments** : There are total 19 variables but not all are used in our analysis, we will shortly remove the irreverent columns. Some major columns are vital for this analysis are Trip distance, Trip duration, Fare amount , Tip amount, Passenger count and Vendor ID.

```{r, results='markup',echo=FALSE}
xkabledply(head((zone_lookup)),bso='bordered', title = 'Zones')
```

##### **Comments:** For this analysis NYC has been divided 6 Borough and 261 distinct Zones.
  
### 2.3 Data Statistics

```{r Checking Data types, results='markup',echo=FALSE}

# Deep dive into data
str(raw_data)

str(zone_lookup)

```

### 2.4 Data Manipulation

```{r Excess columns Removal,echo=FALSE}


drop <- c("store_and_fwd_flag", "extra", "mta_tax","improvement_surcharge","congestion_surcharge","airport_fee","total_amount")

raw_data <- raw_data[,!(colnames(raw_data) %in% drop)]
```



```{r Renaming columns,echo=FALSE}
colnames(raw_data)[2] <- 'pickup_time'
colnames(raw_data)[3] <- 'dropoff_time'
colnames(raw_data)[7] <- 'PULocation'
colnames(raw_data)[8] <- 'DOLocation'
```

```{r Summary for Raw Data,echo=FALSE}
#xkablesummary(raw_data,bso = 'bordered', title = 'Raw Data Summary', pos = 'center')
```

#### 2.4.1 Look up values

```{r PU and DO Loop up,echo=FALSE}

# Looking up Zone for Zone IDs 

raw_data <- inner_join(raw_data,zone_lookup,by=c('PULocation' = 'LocationID'))

# Dropping irrelevant column added from above join

drop <- c('Zone','service_zone','PULocation')


raw_data <- raw_data[,!(colnames(raw_data) %in% drop)]

colnames(raw_data)[12] <- 'PULocation'

# Performing above exercise for drop off location

raw_data <- inner_join(raw_data,zone_lookup,by=c('DOLocation' = 'LocationID'))

drop <- c('Zone','service_zone','DOLocation')

raw_data <- raw_data[,!(colnames(raw_data) %in% drop)]

colnames(raw_data)[12] <- 'DOLocation'

```

##### Looking up Location names to the corresponding location ids such as 1-EWR, 2-Queens, 3- Bronx.

#### 2.4.2 Calculated column of interest

```{r tip percentage,echo=FALSE}

# Adding tip percentage

raw_data['tip_perc'] <- c(round((raw_data$tip_amount/raw_data$fare_amount)*100,0))

# Adding trip duration

raw_data['trip_duration'] <- c(minute(seconds_to_period(raw_data$dropoff_time - raw_data$pickup_time))) +c(hour(seconds_to_period(raw_data$dropoff_time - raw_data$pickup_time))*60)

# Adding day of the week

raw_data['day'] <- c(wday(raw_data$pickup_time,label=TRUE))

```

```{r Pick up time period,echo=FALSE}

# Creating cut-off times

breaks <- hour(hm("00:00", "6:00", "12:00", "18:00", "23:59"))

# Creating labels for cut off time

labels <- c("Night", "Morning", "Afternoon", "Evening")

# Calculating the time period based on the pick up time

raw_data['PU_time_of_day'] <- cut(x=hour(raw_data$pickup_time), breaks = breaks, labels = labels, include.lowest=TRUE)

# Changing the variable as categorical

raw_data$PU_time_of_day <- as.factor(raw_data$PU_time_of_day)

```

```{r Drop off time period,echo=FALSE}

# Calculating the time period based on the drop off time

raw_data['DO_time_of_day'] <- cut(x=hour(raw_data$dropoff_time), breaks = breaks, labels = labels, include.lowest=TRUE)

# Changing the variable as categorical

raw_data$DO_time_of_day <- as.factor(raw_data$DO_time_of_day)

```

##### Calculating columns of interest such as Trip duration, Trip percentage and Day

#### 2.4.3 Missing vaules

```{r,echo=FALSE}

# Summary for NA values

xkabledply(data.frame(colSums(is.na(raw_data))),bso='bordered', title = 'NA Summary Pre-Cleaning', pos = 'center')

# Investigating Tip percentage

raw_data[is.na(raw_data$tip_perc),]

# On Investigating, it is found that there are trips with no fare amount and, by extension, no tips. Hence we will drop these values.

raw_data <- raw_data[!is.na(raw_data$tip_perc),]

# Investigating Passenger Count and RatecodeID

raw_data[is.na(raw_data$passenger_count),]

# We can drop records for which the number of passengers was not recorded, as this will tamper with our analysis of fare amount and tip percentage.

raw_data <- raw_data[!is.na(raw_data$passenger_count),]

xkabledply(data.frame(colSums(is.na(raw_data))),bso='bordered', title = 'NA Summary Post-Cleaning', pos = 'center')
```

##### Dealing with missing values

#### 2.4.4 Defining categorical variables

```{r,echo=FALSE}

colnames(raw_data)

raw_data$VendorID <- as.factor(raw_data$VendorID)

raw_data$RatecodeID <- as.factor(raw_data$RatecodeID)

raw_data$payment_type <- as.factor(raw_data$payment_type)

raw_data$PULocation <- as.factor(raw_data$PULocation)

raw_data$DOLocation <- as.factor(raw_data$DOLocation)

raw_data$day <- as.factor(raw_data$day)


```

##### Defining variables such as vendor id ,passenger count, pick-up and Drop-off location as Categorical Variables.

#### 2.4.5 Outliers

```{r Cleaning Data,echo=FALSE}

# Glimpse into the summary for the raw data.

xkablesummary(raw_data,bso='bordered', title = 'Summary of Raw Data', pos = 'center')

# Looking at the above summary, following observations are considered while dealing with outliers.
# 1. Passenger_count seems to go up to nine, which seems incorrect; hence, we will consider passengers up to 6.
# 2. The trip distance has a maximum value of 184341 miles, more than the entire United States. Therefore we consider trip distances up to 40 miles.
# 3. RatecodeID, according to our data, can be only six values; however, the data contains values beyond six. These values are neglected.
# 4. The fare amount ranges from -907 to 395845. Unless someone is too generous, these values are incorrect. The range for fare amount is considered from 0 to 150.
# 5. Similarly considering the range 0-100 for the tipping amount and toll collected.
# 6. The unknown values for the pick-up and drop-off locations are dropped.
# 7. When considering the payment type, only credit card payments are referenced.
# 8. Finally, values beyond the 500% tipping percentage looks skeptical; hence we will ignore these values and consider up to a 60% tipping ratio.

# Categorical variables check.

unique(raw_data$VendorID)
unique(raw_data$PULocation)
unique(raw_data$DOLocation)
unique(raw_data$RatecodeID)

# Numeric Variables check

raw_data[raw_data$tip_perc > 100,]

max(raw_data$fare_amount)
min(raw_data$fare_amount)
raw_data[raw_data$fare_amount > 150,]

max(raw_data$trip_distance)
min(raw_data$trip_distance)
raw_data[raw_data$trip_distance > 125,]

max(raw_data$tip_amount)
min(raw_data$tip_amount)
raw_data[raw_data$tip_amount > 80,]

max(raw_data$tolls_amount)
min(raw_data$tolls_amount)
raw_data[raw_data$tolls_amount > 80,]

raw_data[raw_data$PULocation == 'Unknown',]

raw_data[raw_data$DOLocation == 'Unknown',]

max(raw_data$tip_perc)
min(raw_data$tip_perc)
raw_data[raw_data$tip_perc > 100,]

# cleaning the final data

clean_data <- 
  raw_data %>% filter(
  (RatecodeID != 99)  		  & 
  (payment_type == 1)       &
  (PULocation != 'Unknown') & 
  (DOLocation != 'Unknown') &
  (passenger_count > 0) 	  & (passenger_count <= 6) &
  (trip_distance > 0) 		  & (trip_distance <150) 	& 
  (fare_amount > 0) 		    & (fare_amount < 150) 	& 
  (tip_amount > 0) 			    & (tip_amount < 100) 	  & 
  (tolls_amount > 0) 		    & (tolls_amount < 100) 	&  
  (trip_duration > 0) 		  & (trip_duration <= 40) & 
  (tip_perc >0) 			      & (tip_perc < 60))

nrow(clean_data)

```

```{r,echo=FALSE}
#clean_data
sum(clean_data$tip_perc,na.rm = TRUE)
```

##### **Investigating Outliers:** 
##### Looking at the above summary, following observations are considered while dealing with outliers:

1. Passenger_count seems to go up to nine, which seems incorrect; hence, we will consider passengers up to 6.
2. The trip distance has a maximum value of 184341 miles, more than the entire United States. Therefore we consider trip distances up to 40 miles.
3. Rate codeID, according to our data, can be only six values; however, the data contains values beyond six. These values are neglected.
4. The fare amount ranges from -907 to 395845. Unless someone is too generous, these values are incorrect. The range for fare amount is considered from 0 to 150.
5. Similarly considering the range 0-100 for the tipping amount and toll collected.
6. The unknown values for the pick-up and drop-off locations are dropped.
7. When considering the payment type, only credit card payments are referenced because we don't have data for cash tips.
8. Finally, values beyond the 500% tipping percentage looks skeptical; hence we will ignore these values and consider up to a 60% tipping ratio.

```{r,echo=FALSE}
xkabledply(data.frame(colSums(is.na(clean_data))),bso='bordered', title = 'NA Summary Post-Cleaning', pos = 'center')
```

**Summary for Cleaned Data**

```{r Summary for Cleaned Data, results='markup',echo=FALSE}

summary(clean_data)
```

##### The number of observations post data cleaning are ** `r nrow(clean_data)*ncol(clean_data)` **

### 2.5 Distribution Check

```{r Tip Percentage,echo=FALSE}

## The data is approximately normally distributed with slight skewness on the right side.

clean_data %>%
ggplot(aes(tip_perc)) +
  geom_histogram(aes(y =..density..),  colour = "black", fill = "#6a73b6", binwidth = 1) + 
  ggtitle("Distribution of NYC Taxi Tips") +
  stat_function(fun = dnorm, args = list(mean = mean(clean_data$tip_perc), sd = sd(clean_data$tip_perc))) +       
  labs(x= 'Tips', y='Density')

```

##### The distribution of the primary candidate for this study (Tip) is virtually normally distributed, with the lack of some value on the left side.

## 3 Explanatory Data Analysis

### 3.1 Parameter Visualization 

```{r Day Duration,echo=FALSE}

## It looks like the day of the week has no significant impact on the tip percentage.

trips_per_day <- clean_data %>% group_by(day) %>% count()

colnames(trips_per_day)[1] <- 'day'

ggplot(data = trips_per_day, aes(y = n,x=day, fill = day)) +
  geom_col() +  
  labs (x= "Day of the Week", y = "No. of Trips") +
   theme(plot.title = element_text(hjust = 0.5)) +
  ggtitle('Day-wise Distribution of Trips')
```

##### We start by visualizing crucial parameters to determine their importance in our data. 

##### We first take a look at the number of trips segregated by day of the week, coming to the conclusion that most trips occurred on Sunday, Monday, Wednesday, and Thursday.

```{r Vendor Split,echo=FALSE}

## Verifone has a greater number of market share

vendor_split <- clean_data %>% group_by(VendorID) %>% count()


ggplot(vendor_split, aes(x = "", y = n, fill = VendorID)) +
  geom_col(color = "black") +
  geom_label(aes(label = n),
             position = position_stack(vjust = 0.5),
             show.legend = FALSE) +
  coord_polar(theta = "y") +
  scale_fill_manual(values = c("#5A5A5A","#0674C4"),labels=c('Creative Mobile Technologies', 'VeriFone'),name = "Vendor")+
  theme(axis.text = element_blank(),
        axis.title.x = element_blank(),
        axis.title.y = element_blank(),
        axis.ticks = element_blank(),
        panel.grid  = element_blank(),
        plot.title = element_text(hjust = 0.5)) +
  ggtitle('Vendor Split')
```

##### It is observe from the above chart VeriFone has a bigger share of approximately 75% in the yellow taxi rides.


```{r Passenger Trips Count,echo=FALSE}

## The plot is right skewed signifying there are greater number of trips with single passenger.

trips_per_passenger <- clean_data %>% group_by(passenger_count) %>%  count()

ggplot(trips_per_passenger,aes(passenger_count, n, fill = passenger_count)) +
  geom_col() +
  labs(x = "Number of passengers",y ="Total number of trips") +
  scale_fill_gradient(low="#F7BA2C",high="#F3696E") +
  theme(plot.title = element_text(hjust = 0.5),legend.position = "none") +
  ggtitle('Trips by Passenger Count ')
summary(trips_per_passenger)
```

##### The graph above indicates that the number of journeys increases as the number of passengers decreases. The right-skewed graph corroborates this observation.

```{r Distribution for day wise trip count,echo=FALSE}

# select unique entries in the time of day 
lvls <- unique(unlist(clean_data$PU_time_of_day))

# Applying function which segregates the lvls value and count them in each col of dataset. Finally we choose 16 - PU_time_of_day and 17 - DO_time_of_day from the results.

time_period <- sapply(clean_data,function(x) table(factor(x, levels = lvls)))[,16:17]

# Converting index into first column 

time_period <- cbind(dayPeriod = rownames(time_period), time_period)
rownames(time_period) <- 1:nrow(time_period)

# Converting matrix as data frame

time_period <- as.data.frame(time_period)

# Converting variables as categorical for ploting

time_period['PU_time_of_day'] <- as.numeric(unlist(time_period['PU_time_of_day']))
time_period['DO_time_of_day'] <- as.numeric(unlist(time_period['DO_time_of_day']))
time_period['dayPeriod'] <- as.factor(noquote(time_period[,'dayPeriod']))

# For ploting two variables 

df <- melt(time_period, id.vars='dayPeriod')

ggplot(df, aes(x=dayPeriod, y=value, fill=variable)) + 
    geom_bar(stat = "identity",position = "dodge") +
  labs(x = "Time of the Day",y ="Total number of trips") +
  theme(plot.title = element_text(hjust = 0.5)) +
  scale_fill_manual(values = c("#5A5A5A","#0674C4"),labels=c('Pick Up Time', 'Drop Off Time'),name = "Time Category") +
  ggtitle('Distribution of time of the day')
```

##### We had expected that evenings would have the most travels, but our data revealed that afternoons were the busiest in terms of number of trips, followed by mornings. 

### 3.2 Relationship Exploration 

```{r Relationship Exploration,echo=FALSE}

str(clean_data)

melt(cor(clean_data[,unlist(lapply(clean_data, is.numeric))])) %>%
ggplot(aes(x=Var1, y=Var2, fill=value)) + 
  geom_tile() +
  geom_text(aes(Var2, Var1, label = round(value,3)), color = "black", size = 2.5) +
theme(
  axis.title.x = element_blank(),
  axis.title.y = element_blank(),
  axis.text.x = element_text(angle = 45, hjust=1),
  legend.justification = c(0, 1),
  plot.title = element_text(hjust = 0.5))+
  guides(fill = guide_colorbar(barwidth = 1, barheight = 5,
                title.position = "top", title.hjust = 0.5)) +
  scale_fill_manual(name = "Scale") +
  scale_fill_gradient(low="#fff33b",high="#e93e3a") +
  ggtitle('Correlation between Entities')  

```

##### **Observations** - We initially skimmed correlation coefficients for our continuous variables, such as travel distance and trip time, to see if they were connected to tip amount. As seen in the above cor plot, the results were 0.65 and 0.33, which suggest a moderate association. However, since correlation does not imply causation, statistical tests must be performed on these variables to establish their relationship.

### 3.3 Location Analysis

```{r Location wise distribution,echo=FALSE}
lvls <- unique(unlist(clean_data$PULocation))

location_dist <- sapply(clean_data,function(x) table(factor(x, levels = lvls)))[,11:12]

location_dist <- cbind(location = rownames(location_dist), location_dist)
rownames(location_dist) <- 1:nrow(location_dist)

location_dist <- as.data.frame(location_dist)

location_dist['PULocation'] <- as.numeric(unlist(location_dist['PULocation']))
location_dist['DOLocation'] <- as.numeric(unlist(location_dist['DOLocation']))
location_dist['location'] <- as.factor(noquote(location_dist[,'location']))

# For ploting two variables 

df <- melt(location_dist, id.vars='location')

ggplot(df, aes(x=location, y=value, fill=variable)) + 
    geom_bar(stat = "identity",position = "dodge") +
  labs(x = "Location",y ="Total number of trips") +
  theme(plot.title = element_text(hjust = 0.5)) +
  scale_fill_manual(values = c("#5A5A5A","#0674C4"),labels=c('Pick Up Location', 'Drop Off Location'),name = "Location Category") +
  ggtitle('Distribution of Location')
summary(location_dist)
```
```{r,results='markup',echo=FALSE}
#location_freq_dis <-  clean_data %>% group_by(PULocation,DOLocation) %>%  count(sort = T)

location_freq_dis <- clean_data %>% group_by(PULocation,DOLocation) %>%  count(sort = T)

avg_fare <- clean_data %>% group_by(PULocation,DOLocation) %>%  summarise(sum(fare_amount))

avg_fare <- inner_join(location_freq_dis,avg_fare,by=c('PULocation' = 'PULocation', 'DOLocation' = 'DOLocation'))

location_freq_dis['Avg. Fare'] <- avg_fare['sum(fare_amount)'] / avg_fare['n']

colnames(location_freq_dis)[1] <- 'Pick up Location'
colnames(location_freq_dis)[2] <- 'Drop off Location'
colnames(location_freq_dis)[3]   <- 'No. of Trips'

xkabledply(head(location_freq_dis,n=10),bso = 'bordered',title = 'Location Distribution')


```

##### **Observations** - At first glance, Queens has the most pickups, followed by Manhattan and Brooklyn in second and third, respectively. Similarly, Manhattan, Queens, and Brooklyn make up the top three drop-off locations. Further investigation showed that the highest number of trips was between Queens and Manhattan, followed by Manhattan to Queens and Manhattan to Brooklyn. These results are credible when considering yellow cabs (the focus of this analysis), as they primarily serve the above regions, in contrast to green cabs, which serve areas where yellow cabs do not operate. 
##### We can see the highest avg fare price, Staten to Island EWR, which is $102; however, we do not have sufficient data for these locations; hence we consider only the top 10 source and destination boroughs in terms of number of trips. A trip from Manhattan to EWR costs around $66 on average and $46 for travelling within Queens. 

##### Now that we have looked at the insights from our location vs tip percentage data, we explore the statistical significance of the two 

```{r Tip percentage across locations,echo=FALSE}

ggplot(data = clean_data, aes(x = PULocation, y = tip_perc, fill = PULocation)) + 
  ggtitle("Tip Ratio by Pickup Location") + 
  geom_boxplot() + 
  labs(x = "Location", y ="Tip Percentage")+
  theme(plot.title = element_text(hjust = 0.5)) 

ggplot(data = clean_data, aes(x = DOLocation, y = tip_perc, fill = DOLocation)) + 
  ggtitle("Tip Ratio by Drop off Location") + 
  geom_boxplot() + 
  labs(x = "Location", y ="Tip Percentage")+
  theme(plot.title = element_text(hjust = 0.5)) 

```

```{r,echo=FALSE}

ggplot(data = clean_data, aes(x = PULocation, fill = PULocation)) + geom_bar() + ggtitle("Trip Counts Based on Pick UP Location") + labs(x = "Location", y ="Trip Frequency") + theme(plot.title = element_text(hjust = 0.5)) 

ggplot(data = clean_data, aes(x = DOLocation, fill = DOLocation)) + geom_bar() + ggtitle("Trip Counts Based on Dropoff Location") + labs(x = "Location", y ="Trip Frequency") + theme(plot.title = element_text(hjust = 0.5)) 
```

##### This graph illustrates that Queens has the most tipping passengers, followed by Manhattan.Similarly, Manhattan has higher tipping passengers than others in Drop-Off Location

```{r ANOVA Tests for Location, results='markup',echo=FALSE}

anova_puloc_tip <- aov(tip_amount ~ PULocation, data = clean_data)
anova_doloc_tip <- aov(tip_amount ~ DOLocation, data = clean_data)

summary(anova_puloc_tip)
summary(anova_doloc_tip)

```

##### **Observations** - The p-value for both variables is 0.2*10^−15 or 0.0000000000000002, which are infinitesimal compared to the significance level of 0.05, thus rejecting the null hypothesis that the means of the two entities are the same, making them statically different.

### 3.4 Trip Duration Impact on Tips

```{r Trip Duration,echo=FALSE}

## The data is approximately normally distributed with slight skewness on the right side.

clean_data %>%
ggplot(aes(trip_duration)) +
  geom_histogram(aes(y =..density..),  colour = "black", fill = "#6a73b6", binwidth = 1) + 
  ggtitle("Distribution of NYC Taxi Ride Lenghts") +
  stat_function(fun = dnorm, args = list(mean = mean(clean_data$trip_duration), sd = sd(clean_data$trip_duration))) +       
  labs(x= 'Ride Durations', y='Density') 

```


##### **Observations** - The data is approximately normally distributed with slight skewness on the right side. This is to say that majority of out trips are 20-40 mins in length.

```{r,echo=FALSE}

clean_data %>% group_by(trip_duration) %>% summarise_at(vars(tip_perc), list(mean = mean)) %>%
ggplot(aes(x = trip_duration, y = mean, fill= mean)) + 
  geom_col( alpha = 0.6) +
  labs(y = 'Tip Percentage Frequency', x = 'Trip Duration', title = 'Distribution of tip percentages across Trip Duration') +
  theme(plot.title = element_text(hjust = 0.5)) +
  scale_fill_gradient(name = "Tip Frequency")

```



```{r ttest on tip and trip duration,echo=FALSE}

ttest_tip_duration <- t.test(clean_data$tip_perc,clean_data$trip_duration)

ttest_tip_duration
```

##### **Observations** - A t-test between travel time and customer tip percentage reveals the p-value of the relationship between the variables, which is 0.2*10-15; consequently, since the value is much lower than the significance level of 0.05, we can state that Yellow taxi passengers tip differently depending on the length of the trip and successfully reject the null hypothesis that the means of the two variables are equal.

### 3.5 Trip Length and Tips

#### We are attempting to determine if those doing shorter journeys are more likely to leave larger gratuities or those taking longer travels are more giving.

```{r,echo=FALSE}
# Subsetting columns of intrest

trip_len_nature <- subset(clean_data,select = c("tip_amount","trip_distance"))

# We begin by splitting up out data into two segments - Short Trips (0-20 mins) and Long Trips (20-40 mins)

breaks=c(0, mean(clean_data$trip_distance),max(clean_data$trip_distance))

# Creating labels for cut off time

labels <- c("Short Trip", "Long Trip")

# Splitting the trips into segment 

trip_len_nature['Duration_Type'] <- cut(x=as.integer(clean_data$trip_distance), breaks = breaks, labels = labels, include.lowest=TRUE)

trip_len_nature
# Checking for NA values in the new col

trip_len_nature[is.na(trip_len_nature),]

trip_len_nature %>% group_by(trip_distance,tip_amount,Duration_Type) %>% count() %>%
ggplot(aes(x = trip_distance, y = n, fill= Duration_Type)) + 
  geom_col(width = 0.2, alpha = 1) +
  labs(y = 'No of time tiped', x = 'Trip Distance', title = 'Distribution of tip percentages across trip Distance') +
  theme(plot.title = element_text(hjust = 0.5)) +
   scale_fill_manual(values = c("#003f5c","#ffa600"),labels=c('Short Trip', 'Long Trip'),name = "Trip Type") 

```


##### To study these two groups separately, we divide the data for trip distance into two categories: short and long trips. When we plot the journey distance against the number of tips paid, we notice that passengers tips higher number of times on shorter rides than on longer ones.



```{r,echo=FALSE}

melt(trip_len_nature) %>%
ggplot( aes(x = Duration_Type, y = value,fill = Duration_Type))+
  geom_boxplot() +
  stat_summary(fun.y=mean, geom="point", shape=23, size=4) + 
  labs(y = 'Tip Percentage', x = 'Distance Travelled', title = 'Box Plot of tip percentages vs trip Distance') +
  scale_fill_manual(values = c("#003f5c","#ffa600"),labels=c('Short Trip', 'Long Trip'),name = "Trip Type")
  
```


```{r,echo=FALSE}
st <- trip_len_nature[trip_len_nature$Duration_Type == 'Short Trip',] 
dt <- trip_len_nature[trip_len_nature$Duration_Type == 'Long Trip',]
  
str(st)
str(dt)

xkablesummary(st)
xkablesummary(dt)

```

```{r,echo=FALSE}

# A Simple two way test for pvalues which is found to be way less than the significant level 0.05 he

ttest_dis_tip <- t.test(dt$tip_amount , st$tip_amount)

ttest_dis_tip
```


##### **Observations** - A Simple two way test for pvalues which is found to be way less than the significant level 0.05. We can reject the null hypothesis, Z-test cannot be used because we don't know population's mean & std dev.

##### **Declaring hypothesis**

##### Null Hypothesis: Ho Tip amount is same for both short and long distance passenger(s)
##### Alternate Hypothesis: Ha Tip amount is NOT same for both short and long distance passenger(s)

 

### 3.6 Importance of passenger count and vendor

```{r,echo=FALSE}

tip_count_pass <- clean_data %>% group_by(passenger_count) %>% summarise_at(vars(tip_amount), list(count = length))

ggplot(data = tip_count_pass, aes(y = count,x=passenger_count, fill = passenger_count)) +
  geom_col() +  
  labs (x= "Number of Passengers", y = "Tips' Amount") +
   theme(plot.title = element_text(hjust = 0.5)) +
  ggtitle('Passenger-wise Distribution of Tips')

```


```{r,echo=FALSE}

anova_tip_pass <- aov(tip_perc ~ passenger_count , data= clean_data)

summary(anova_tip_pass)
```


##### A Anova test between tip percentage and passenger count shows a significant relationship between the number of passengers and the amount of tips because the p-value is 0.00006, which is less than the significant value(0.005). Hence, we can reject the null hypothesis(H0).


```{r,echo=FALSE}
vendor <- subset(clean_data,select = c("VendorID","tip_perc"))

vendor

  
summary(vendor)
  ggplot(clean_data,aes(VendorID, tip_perc, fill = VendorID)) +
  geom_boxplot() +
  theme(plot.title = element_text(hjust = 0.5)) +
  labs(y = "Tip Amount Percent", x = "Vendor ID") + 
  scale_fill_manual(values = c("#5A5A5A","#0674C4"),labels=c('Creative Mobile Technologies', 'VeriFone'),name = "Vendor") +
  ggtitle("Box plot distribution for Trip Amount Percentage and Vendor")

    

```


##### **Observation- ** Finally, we explore the relationship between the vendor and our response variable, tip. Unsurprisingly a two-way T-test between the aforementioned variables reveals that there is no significance with a p-value of 0.264.


```{r,echo=FALSE}

ttest_vendor = t.test(tip_perc ~ factor(VendorID), data = clean_data)

ttest_vendor
```

## 4 Conclusion

##### We conclude our analysis by discussing the limitations and Future scopes of this project

#### Limitations

1. Daylight savings are not considered
2. In this will not consider large dataset (hardware )
3. In this there is no cash Tips are considered
4. There are more variables to consider such as Gender and Weather
5. human error in data
6. Central Limit Theorem (CLT) states that sample means of moderately large samples are often well-approximated by a normal distribution even if the data is not normally distributed. Our dataset contains a significant amount of observations thus qualifying it to be approximately normal under CLT. 

#### Future scope 

##### The dataset produced for this project will serve as the foundation for future study. More insights will be obtained by analyzing at least a year's worth of data. If weather impacts the amount of rides, hourly weather data combined with weather events may provide further information. A forecast and prediction based on zones, as well as boroughs, will make it extremely easy for drivers to be present at any particular moment in time and Gender and Driver and Trip Rating.


Feature (variable)  |  Test  |  P-value  | Null Hypothesis (H0)  | Decision on H0 |  
--------|-----|-----|--------|--------|  
 pickup location | ANOVA | `r format(summary(anova_puloc_tip)[[1]][["Pr(>F)"]][[1]], digits= 3 )` | means are equal | reject H0 |  
 dropoff location | ANOVA | `r format(summary(anova_doloc_tip)[[1]][["Pr(>F)"]][[1]], digits = 9)` | means are equal | reject H0 |  
 distance | T-Test | `r format(ttest_dis_tip$p.value, digits= 9 )` | means are equal | reject H0 |  
 passenger count | ANOVA | `r format(summary(anova_tip_pass)[[1]][["Pr(>F)"]][1], digits= 3)` | means are equal | reject H0 |
 vendor ID | T-test | `r format(ttest_vendor$p.value, digits= 3)` | means are equal | failed to reject H0 | 
