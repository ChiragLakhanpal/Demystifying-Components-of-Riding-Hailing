# 4 Model Building

We began by selecting linear (univariate and multivariate) regression models to examine how they fit our data. Linear regression is a conventional, common approach that may explain the association with tip well, so we chose to test it first. To strengthen our linear model, we also used step-by-step feature selection, lasso, ridge, and principal component analysis (PCA). We also made use of decision trees. The capacity of decision trees to mimic non-linear connections is one of its advantages. According to our EDA, journey duration, distance, and fare are all linearly connected over small distances, but this connection weakens over longer distances due to the involvement of other possible factors.Consequently, there may be in fact a non-linear relationship with tip, too.

## 4.1 Preparation

We prepped our data for modeling before developing our models by using one hot encoding, establishing training and testing sets, and scaling our data.

### 4.1.1 One hot encoding 

We employed one hot encoding to convert factor columns to numerical columns. All factors will be converted into a distinct boolean column by a single hot encoding.

Post One Hot Encoding (OHE) we are now left with **`r dim(dataset)[2]` columns**. 

### 4.1.2 Scaling variables

Because the magnitude of the values may not be proportionate, we must scale the numerical variables in our datasets. For comparative reasons, we compute the mean and standard deviation of each numerical column.
### 4.1.3 Test train split

In order to eliminate any bias in test results while utilizing train data, the train-test split should be implemented before (most) data modeling. We randomly divided the dataset into 70% train and 30% test to replicate a train and test set.
## 4.2 Evaluation Metrics

*From Wikipedia*

1. **Mean Absolute Percentage Error (MAPE)**

|               The mean absolute percentage error (MAPE), also known as mean absolute percentage deviation (MAPD), is a measure of prediction 
|               accuracy of a forecasting method in statistics. It usually expresses the accuracy as a ratio defined by the formula:

|               \n![](Mape.svg)

2. **Akaike information criterion (AIC)**

|               The Akaike information criterion is an estimator of prediction error and thereby relative quality of statistical models for a 
|               given set of data.Given a collection of models for the data, AIC estimates the quality of each model, relative to each of the  
|               other models.:

|               \n![](AIC.svg)

3. **R squared (R^2^)**

|               In statistics, the coefficient of determination, denoted R2 or r2 and pronounced "R squared", is the proportion of the variation 
|               in the dependent variable that is predictable from the independent variable(s).

|               \n![](R-squared.svg)
## 4.3 Tip Percentage
The subsequent step post preparing our data is to employ a number of regression-based methods to extract insights from data, which we can then use to predict which result is likely to hold true for our target variable based on training data.
### 4.3.1 Principal component analysis
We chose PCA as a variable reduction strategy because the majority of our variables were associated with one another and there were 48 features.

Variables graph. Variables that are positively associated point to the same side of the plot. Negatively associated variables point to the graph's opposing sides.

**Observations:** Even if the components explain 93.4% of the variance in the data, that may not necessarily mean that a good R^2^ or high coefficients will result. Hence to investigate this, we evaluated this; we proceed to build out Linear regression mode.

### 4.3.2 Linear regression
**ANOVA tests on all the three models**
**Treating Outliers and Modeling**
### 4.3.3 Lasso regression
### 4.3.4 Ridge regression
### 4.3.5 Decision tree
**Cost complexity criterion**
##### Pruned Decision Tree
### 4.3.6 Random Forest
### 4.3.7 Summary and analysis

## 4.4 Tip Amount
